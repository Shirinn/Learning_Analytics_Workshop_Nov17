{"cells":[{"cell_type":"markdown","source":["# Finding Causality in Big Data: An Introduction"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":["### Shirin Mojarad, Ph.D.\n### Data Scientist, McGraw-Hill Education\n\n@shirinmojarad\n\nShirin.mojarad@gmail.com\n\nhttps://github.com/Lewkow/LAK_2017_Workshop"],"metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":["# Agenda \n\n* Introduction to causality\n* How to establish causality\n* Randomized controlled trials\n* Causal inference\n* Your Toolkit For Finding Causality"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":["# Your Toolkit For Finding Causality"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":["# Causal Inference in 5 Steps\n\n<ol type=\"1\">\n<li>Identify covariates from observational data</li>\n<li>Choose a matching metric </li>\n<li>Execute a matching algorithm</li>\n<li>Examine covariate balance</li>\n<li>Estimate treatment effects </li>\n</ol>"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":["# Data\n\nWe want to study the effect of a training program on individuals’ earnings.\n\n* Data are from the National Supported Work Demonstration (NSWD) and the Current Population Survey (Dehejia and Wahba survey 2002)\n* Treatment is if a person received training \n* Independent variables are age, education, marrital status, earnings in 1974 and 1975, employement status in 1974 and 1975\n* Outcome is real earnings in 1978 (RE78)\n* We need to find matches for the 185 treated observations and then compare outcomes"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":["## Import required libraries and data"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport statsmodels.stats.api as sms\nfrom sklearn.linear_model import LogisticRegression\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, hypergeom, gaussian_kde\nfrom scipy.stats import ttest_ind\nimport math\nfrom scipy.stats import binom, hypergeom, gaussian_kde\nimport matplotlib.patches as mpatches"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":["df = sqlContext.sql(\"SELECT * FROM matching_earnings_1\").toPandas()\nprint(df.shape)\ndf.head()"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":["print 'Number of treated units: %d' %df.groupby('TREAT').size()[1]\nprint 'Number of control units: %d' %df.groupby('TREAT').size()[0]"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Note from the output that not all of the control observations might be used as matches for the 185 treated observations."],"metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":["## Convert numeric columns to integer type"],"metadata":{}},{"cell_type":"code","source":["# several numeric columns are shown with type object instead of integer\ndf.dtypes"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# function to convert dataframe column types to float\ndef convertFloat(data):\n  for attribute in data.columns:\n    data[attribute] = data[attribute].astype(float) \n  return data"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# apply the above function\ndf = convertFloat(df)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["## Define treatment, outcome and covariates"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["# treatment\nTr = df.TREAT\n\n# outcome\nY = df.EARNINGS\nY0 = df.EARNINGS[df.TREAT==0]\nY1 = df.EARNINGS[df.TREAT==1]\n\n# covariates\nX = df[['AGE', 'EDUC', 'MARR','NODEGREE','RE74','RE75','U74','U75']]"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["# 1 Identify covariates from observational data\n## 1.1 Difference-in-means: outcome variable\n\n* Effectiveness of treatment (effect on RE78 expression)\n* Question: does treatment affect RE78 expression (outcome)?"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["df.groupby('TREAT')['EARNINGS'].mean().reset_index()"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# Mean difference \nprint 'Differene in means: $'+ str(int(Y1.mean() - Y0.mean())) "],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["It seems that individuals who did not receive training earn $15k on average more than those who received the training."],"metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"code","source":["# t-statistic & p-value for difference in outcome of two groups\ndef hypothesisTest(data, attribute, group):\n    x = data[attribute][df[group]==1]\n    y = data[attribute][df[group]==0]\n    # t-statistic & p-value for difference in outcome of two groups\n    t = ttest_ind(x, y)[0]\n    p = ttest_ind(x, y)[1]\n    # Confidence intervals\n    cm = sms.CompareMeans(sms.DescrStatsW(x), sms.DescrStatsW(y))\n    CI = str(round(cm.tconfint_diff(usevar='unequal')[0]))+' - '+str(round(cm.tconfint_diff(usevar='unequal')[1]))\n    # Cohen's d\n    pooledvar = math.sqrt((pow(x.std(),2) + (pow(y.std(),2)))/2)\n    d = (x.mean()-y.mean()) / pooledvar\n    # create dataframe\n    tablelist = []\n    tablerow = [attribute,x.mean()-y.mean(),t,p,CI,d]\n    tablelist.append(tablerow)\n    out = pd.DataFrame(tablelist)\n    out.columns = ['Attribute','Mean Difference','t-value','p-value','95% Confidence Intervals',\"Cohen's d\"]\n\n    return out"],"metadata":{"collapsed":true,"slideshow":{"slide_type":"slide"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":["hypothesisTest(df, 'EARNINGS', 'TREAT')"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["The difference-in-means is significant and the effect size is large."],"metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":["# 1.3 Difference-in-means: pre-treatment covariates\n### We’ll work with the following covariates:\n\n* Age\n* Education\n* Race (Black/White)\n* Marital status\n* Whether or not the subject has a college degree\n* Whether or not the subject was unemployed in 1974 and 1975\n* Earnings in 1974 and 1975\n\nLet’s get the difference-in-means for each of these covariates, by the treatment status:"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["def plotDisribution(data, attribute, groups):\n  f, ax = plt.subplots(figsize=(10, 6))\n  pre = pd.DataFrame({'groups':data[groups], 'propensity':data[attribute]})    \n\n  density0 = gaussian_kde(pre.propensity[pre.groups==0])\n  density1 = gaussian_kde(pre.propensity[pre.groups==1])\n  xs = np.linspace(0,data[attribute].max(),1000)\n  ax.plot(xs,density0(xs),color='blue')\n  ax.fill_between(xs,density1(xs),color='gray')\n  ax.set_title('Before Matching')\n  ax.set_xlabel(attribute)\n  ax.set_ylabel('Density')\n  \n  gray_patch = mpatches.Patch(color='gray', label='Treated')\n  blue_patch = mpatches.Patch(color='blue', label='Not Treated')\n  plt.legend(handles=[gray_patch,blue_patch], loc='center left',bbox_to_anchor=(1, 0.5),fontsize=8)\n  \n  return(f)"],"metadata":{"collapsed":false,"scrolled":false,"slideshow":{"slide_type":"skip"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":["f=plotDisribution(df,'AGE', 'TREAT'); display(f)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["f=plotDisribution(df,'EDUC', 'TREAT'); display(f)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# Exercise: plot the distribution for the rest of covariate for treatment and control groups\nf=plotDisribution(df,'NODEGREE', 'TREAT'); display(f)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["f=plotDisribution(df,'RE74', 'TREAT'); display(f)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["f=plotDisribution(df,'RE75', 'TREAT'); display(f)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# difference of means for each attribute, by treatment group\ndf.groupby('TREAT').mean().reset_index()"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["* What do you see? Take a moment to reflect on what these differences suggest for the relationship of interest (that between treated and not treated)."],"metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":["We can carry out t-tests to evaluate whether these means are statistically distinguishable:"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["b = pd.DataFrame()\nfor att in X:\n    a = []\n    a = hypothesisTest(df, att, 'TREAT')\n    b = pd.concat([b,a],0)\nb"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["## 2 Propensity score matching\n\nMatch treated and untreated observations on the estimated probability of being treated (propensity score)\n\nP(X) = Pr (Tr=1|X)\n\nWe can estimate the propensity scores using logistic regression."],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["####### Using GLM\nimport statsmodels.genmod.generalized_linear_model as sm\nglm_binom = sm.GLM(Tr, X, family=sm.families.Binomial())\nres = glm_binom.fit()\nprint res.summary()\npropensityScoreGLM = res.fittedvalues\ndf = pd.concat([df[['TREAT']],X,df[['EARNINGS']],propensityScoreGLM],1)\ndf.columns = np.concatenate(( ['TREAT'],X.columns,['EARNINGS' ,'Propensity Score']), axis=0)\nprint '\\n'+ 'Propensity Scores added: '\ndf.head()"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["## 3 Execute a matching algorithm\n\nThere are several variants of matching: \n* one-to-one matching\n* one-to-many matching \n* with or without a caliper, and with or without replacement\n\nVariants of the methods are examined in the following paper:\n\n</br> Austin, P. C. (2014), A comparison of 12 algorithms for matching on the propensity score. Statist. Med., 33: 1057–1069. doi: 10.1002/sim.6004"],"metadata":{"collapsed":true,"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["# one-to-one matching\nN = len(Tr)\nN1 = Tr[Tr == 1].index; N2 = Tr[Tr == 0].index\ng1, g2 = propensityScoreGLM[Tr == 1], propensityScoreGLM[Tr == 0]\n\n## Check if treatment groups got flipped - the smaller should correspond to N1/g1\nif len(N1) > len(N2):\n   N1, N2, g1, g2 = N2, N1, g2, g1\n\n## match treatment and control group\nmatches = {}\ncaliper = False\nreplace = False\n\nfor m in N1:\n    dist = abs(g1[m] - g2)\n    if (dist.min() <= caliper) or not caliper:\n            matches[m] = dist.argmin()  \n            if not replace:\n                g2 = g2.drop(matches[m])\n\nprint 'Sample matches: '\n{k: matches[k] for k in matches.keys()[:5]}"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":["# Matched data:\ntr = matches.keys()\nctrl = matches.values()\ntemp = pd.concat([df.ix[tr],df.ix[ctrl]])\ndf_matched = temp.groupby(temp.index).first()\ndf_matched.groupby('TREAT').size().reset_index()"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["## 4 Examine covariate balance\n### 4.1 Visual inspection\n\nPlot density of propensity scores and covariates for each group before and after matching"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["from scipy.stats import binom, hypergeom, gaussian_kde\nimport matplotlib.patches as mpatches\ndef plotMatching(data, attribute, groups, matches):\n  f, ax = plt.subplots(1, 2, figsize=(10, 6))\n  pre = pd.DataFrame({'groups':data[groups], 'propensity':data[attribute]})    \n\n  tr = matches.keys()\n  ctrl = matches.values()\n  temp = pd.concat([pre.ix[tr], pre.ix[ctrl]])\n  post = temp.groupby(temp.index).first()\n\n\n  density0 = gaussian_kde(pre.propensity[pre.groups==0])\n  density1 = gaussian_kde(pre.propensity[pre.groups==1])\n  xs = np.linspace(0,data[attribute].max(),1000)\n  ax[0].plot(xs,density0(xs),color='blue')\n  ax[0].fill_between(xs,density1(xs),color='gray')\n  ax[0].set_title('Before Matching')\n  ax[0].set_xlabel(attribute)\n  ax[0].set_ylabel('Density')\n\n  density0_post = gaussian_kde(post.propensity[post.groups==0])\n  density1_post = gaussian_kde(post.propensity[post.groups==1])\n  xs = np.linspace(0,data[attribute].max(),1000)\n  ax[1].plot(xs,density0_post(xs),color='blue')\n  ax[1].fill_between(xs,density1_post(xs),color='gray')\n  ax[1].set_title('After Matching')\n  ax[1].set_xlabel(attribute)\n  ax[1].set_ylabel('Density')\n  \n  gray_patch = mpatches.Patch(color='gray', label='Treatment')\n  blue_patch = mpatches.Patch(color='blue', label='Control')\n  plt.legend(handles=[gray_patch,blue_patch], loc='center left',bbox_to_anchor=(1, 0.5),fontsize=8)\n  \n  return(f)"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":["f = plotMatching(df, 'Propensity Score', 'TREAT', matches);display(f)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["f = plotMatching(df, 'AGE', 'TREAT', matches);display(f)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["f = plotMatching(df, 'EDUC', 'TREAT', matches);display(f)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["f = plotMatching(df, 'MARR', 'TREAT', matches);display(f)"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["f = plotMatching(df, 'NODEGREE', 'TREAT', matches);display(f)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["f = plotMatching(df, 'RE74', 'TREAT', matches);display(f)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["f = plotMatching(df, 'RE75', 'TREAT', matches);display(f)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["f = plotMatching(df, 'U74', 'TREAT', matches);display(f)"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["f = plotMatching(df, 'U75', 'TREAT', matches);display(f)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["### 4.2 Difference-in-means"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["def balanceCheck(data, attribute, group):\n    means = data[[group, attribute]].groupby(group).mean().reset_index()\n    dist = abs(means.diff()).ix[1]\n    std = data[[group, attribute]].groupby(group).std().reset_index()\n    n = data[group].value_counts()\n    se = std.apply(lambda(s): np.sqrt(s[0]**2/n[0] + s[1]**2/n[1]))\n    tablelist = []\n    tablerow = [attribute,dist[1],se[1]]\n    tablelist.append(tablerow)\n    out = pd.DataFrame(tablelist)\n    out.columns = ['Attribute','difference of means by group','Standard error for covariates by group']\n    return out"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":["b = pd.DataFrame()\nfor att in X:\n    a = []\n    a = balanceCheck(df, att, 'TREAT')\n    b = pd.concat([b,a],0)\nb"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"skip"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":["b = pd.DataFrame()\nfor att in X:\n    a = []\n    a = hypothesisTest(df_matched, att, 'TREAT')\n    b = pd.concat([b,a],0)\nb"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"slide"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":["Difference in means for covariates is not significant anymore and the effect sizes are negligible."],"metadata":{"slideshow":{"slide_type":"fragment"}}},{"cell_type":"markdown","source":["## 5 Estimate treatment effects\n\nEstimate average treatment effect  on the treated\n\n### 5.1 Computes ATT using difference in means"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["# Matched outcome\nY0_matched = df_matched.EARNINGS[df.TREAT == 0]\nY1_matched = df_matched.EARNINGS[df.TREAT == 1]\n\nprint 'Differene in means: $'+ str(int(Y1_matched.mean() - Y0_matched.mean())) "],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":58}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.10","nbconvert_exporter":"python","file_extension":".py"},"name":"Causal-Inference-in-Python","notebookId":32206,"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"celltoolbar":"Slideshow"},"nbformat":4,"nbformat_minor":0}
